{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4xIvWSf_O3MW"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import dcMinMaxFunctions as dc\n",
        "# import dcor\n",
        "from scipy.misc import derivative\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"data/Churn_Modelling.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
              "0             1    15634602   Hargrave          619    France  Female   42   \n",
              "1             2    15647311       Hill          608     Spain  Female   41   \n",
              "2             3    15619304       Onio          502    France  Female   42   \n",
              "3             4    15701354       Boni          699    France  Female   39   \n",
              "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
              "...         ...         ...        ...          ...       ...     ...  ...   \n",
              "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
              "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
              "9997       9998    15584532        Liu          709    France  Female   36   \n",
              "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
              "9999      10000    15628319     Walker          792    France  Female   28   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0          2       0.00              1          1               1   \n",
              "1          1   83807.86              1          0               1   \n",
              "2          8  159660.80              3          1               0   \n",
              "3          1       0.00              2          0               0   \n",
              "4          2  125510.82              1          1               1   \n",
              "...      ...        ...            ...        ...             ...   \n",
              "9995       5       0.00              2          1               0   \n",
              "9996      10   57369.61              1          1               1   \n",
              "9997       7       0.00              1          0               1   \n",
              "9998       3   75075.31              2          1               0   \n",
              "9999       4  130142.79              1          1               0   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "0           101348.88       1  \n",
              "1           112542.58       0  \n",
              "2           113931.57       1  \n",
              "3            93826.63       0  \n",
              "4            79084.10       0  \n",
              "...               ...     ...  \n",
              "9995         96270.64       0  \n",
              "9996        101699.77       0  \n",
              "9997         42085.58       1  \n",
              "9998         92888.52       1  \n",
              "9999         38190.78       0  \n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tHXngvYhO3MX"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"data/Churn_Modelling.csv\")\n",
        "# df=df.drop(['duration', 'pdays'],axis=1) # duration gives away the answer, and pdays has too much missing info\n",
        "\n",
        "X = df.loc[:, df.columns != 'Exited'].replace(dict(yes=True, no=False))\n",
        "Y = df.loc[:, ['Exited']].replace(dict(yes=True, no=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
        "numerical_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "outputs = ['Exited']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "for category in categorical_columns:\n",
        "    df[category] = df[category].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def OHE(x):\n",
        "    dim = max(x)\n",
        "    y = np.zeros((len(x),dim+1))\n",
        "    for i in range(len(x)):\n",
        "        y[i][x[i]] = 1\n",
        "    return(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "geo = OHE(df['Geography'].cat.codes.values)\n",
        "gen =  np.asarray(df['Gender'].cat.codes.values)\n",
        "hcc =  np.asarray(df['HasCrCard'].cat.codes.values)\n",
        "iam =  np.asarray(df['IsActiveMember'].cat.codes.values)\n",
        "\n",
        "categorical_data = np.stack(( gen, hcc, iam), axis=1)\n",
        "# categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
        "numerical_data = np.stack([df[col].values for col in numerical_columns], 1)\n",
        "# numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
        "X = np.concatenate((numerical_data, categorical_data,geo), axis=1)\n",
        "Y = df[outputs].values\n",
        "# outputs = torch.tensor(df[outputs].values).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "    x_normed = x / x.max(0, keepdim=True)[0]\n",
        "    return x_normed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.Tensor(X)\n",
        "Y = torch.Tensor(Y)\n",
        "X = normalize(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RSikHVAlO3MY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gau_ker(u):\n",
        "    return torch.pow(2*torch.tensor(torch.pi),u.shape[1]/(-2))*torch.exp(torch.bmm(u.view(u.shape[0], 1, u.shape[1]), u.view(u.shape[0],  u.shape[1],1))/(-2))\n",
        "def py_kde(x,X_t,h):\n",
        "    norm = (X_t.shape[0]*(h**x.shape[1]))\n",
        "    prob = torch.zeros(x.shape[0]).cuda() \n",
        "    for i in range(len(X_t)):\n",
        "        # print(((x - X_t[i])/h).shape)\n",
        "        # print((gau_ker1((x - X_t[i])/h)).shape)\n",
        "        prob+= torch.squeeze(gau_ker((x - X_t[i])/h)).cuda() /norm\n",
        "    return(prob)\n",
        "def py_kde_der(x,X_t,h):\n",
        "    f = py_kde(x,X_t,h)\n",
        "    f_der = torch.autograd.grad(f,x,torch.ones_like(f),allow_unused=True,create_graph=True)[0].cuda() \n",
        "    return(f_der)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 5.4011e-05, -4.6064e-05,  3.6290e-04,  ..., -1.1709e-04,\n",
            "          5.4471e-05,  6.2621e-05],\n",
            "        [ 2.7061e-05, -8.1394e-06,  1.7736e-04,  ...,  8.1016e-05,\n",
            "          4.2288e-05, -1.2330e-04],\n",
            "        [ 1.8341e-04, -4.6006e-05, -2.7160e-04,  ..., -1.0687e-04,\n",
            "          6.1220e-05,  4.5651e-05],\n",
            "        ...,\n",
            "        [-6.2596e-05,  2.8937e-05, -1.5396e-04,  ..., -7.2275e-05,\n",
            "          3.3666e-05,  3.8610e-05],\n",
            "        [-1.4495e-04, -3.4994e-05,  1.7912e-04,  ...,  1.4910e-04,\n",
            "         -2.2135e-04,  7.2246e-05],\n",
            "        [-2.1991e-04,  1.4414e-04,  1.0738e-04,  ..., -1.2451e-04,\n",
            "          6.9240e-05,  5.5268e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = X.detach().clone().cuda() \n",
        "h =0.65\n",
        "x.requires_grad = True\n",
        "f = py_kde(x,x,h)\n",
        "f_der = py_kde_der(x,x,h)\n",
        "print(f_der)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self,p):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        self.loss_reg = 0\n",
        "        self.p =p\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        self.H_net1 = nn.Sequential(\n",
        "            nn.Linear(12, 48),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(48, 24),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(24, 144)\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        self.X_net = nn.Sequential(\n",
        "            nn.Linear(12, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        def H_mul(z):\n",
        "            H12 = self.H_net1(z)\n",
        "            H12= H12.reshape(z.shape[0],d,d)\n",
        "      \n",
        "            x12 = torch.matmul(z,H12)\n",
        "            return(x12)\n",
        "\n",
        "        def batch_jacobian(func, z, create_graph=False):\n",
        "            # x in shape (Batch, Length)\n",
        "            def _func_sum(z):\n",
        "                return func(z).sum(dim=0)\n",
        "            return torch.squeeze(torch.autograd.functional.jacobian(_func_sum, z, create_graph=create_graph)).permute(1,0,2)\n",
        "        \n",
        "        p = self.p \n",
        "        d = x.shape[1]\n",
        "        bs = x.shape[0]\n",
        "        x.requires_grad =True\n",
        "        self.zero_grad(set_to_none=True)\n",
        "        self.x = x\n",
        "        x= torch.unsqueeze(x,1)\n",
        "        z =x.cuda() \n",
        "        loss_reg = torch.zeros(x.shape[0],d).cuda() \n",
        "        for i in range(p):\n",
        "            #write below code without numbers\n",
        "            self.H_net1 = self.H_net1.cuda()\n",
        "            H = self.H_net1(z).cuda() \n",
        "            H= H.reshape(z.shape[0],d,d)\n",
        "            z = torch.matmul(z,H).cuda() \n",
        "            J = batch_jacobian(H_mul, z, create_graph=True).cuda() \n",
        "            J_int =-torch.log(torch.abs(torch.det(J))).cuda() \n",
        "            loss_reg = loss_reg + torch.squeeze(torch.autograd.grad(J_int, x,torch.ones_like(J_int),allow_unused=True,create_graph= True)[0]).cuda() \n",
        "        self.loss_reg = loss_reg\n",
        "\n",
        "\n",
        "        self.y = z\n",
        "        self.X_net = self.X_net.cuda()\n",
        "        y = self.X_net(z)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVIDIA RTX A4000'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.5659]],\n",
              "\n",
              "        [[0.5797]],\n",
              "\n",
              "        [[0.5501]]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = Net(5)\n",
        "net(X_train[0:3].cuda() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cCPV_zl0O3Mc"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss(reduction= 'none')\n",
        "def my_loss(y_pred,y_train,reg_loss):\n",
        "    loss = criterion(y_pred,y_train) +reg_loss\n",
        "    return loss\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "net_5 = Net(5)\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch number: 0 LR : 0.001  Loss: tensor(3.4557, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9381, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 1 LR : 0.001  Loss: tensor(3.4023, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9369, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 2 LR : 0.001  Loss: tensor(3.3859, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9364, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 3 LR : 0.001  Loss: tensor(3.3705, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 4 LR : 0.001  Loss: tensor(3.3613, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9354, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 5 LR : 0.001  Loss: tensor(3.3554, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9349, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 6 LR : 0.001  Loss: tensor(3.3518, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9343, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 7 LR : 0.001  Loss: tensor(3.3500, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9338, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 8 LR : 0.001  Loss: tensor(3.3488, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9333, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 9 LR : 0.001  Loss: tensor(3.3476, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9327, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 10 LR : 0.001  Loss: tensor(3.3466, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9322, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 11 LR : 0.001  Loss: tensor(3.3454, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9317, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 12 LR : 0.001  Loss: tensor(3.3444, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9311, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 13 LR : 0.001  Loss: tensor(3.3433, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9305, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 14 LR : 0.001  Loss: tensor(3.3423, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9299, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 15 LR : 0.001  Loss: tensor(3.3413, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9293, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 16 LR : 0.001  Loss: tensor(3.3404, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9287, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 17 LR : 0.001  Loss: tensor(3.3395, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 18 LR : 0.001  Loss: tensor(3.3385, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9275, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 19 LR : 0.001  Loss: tensor(3.3377, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.9268, device='cuda:0', grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data=X.cuda() \n",
        "epochs = 20\n",
        "y = Y.cuda()\n",
        "opt1 = torch.optim.Adam(net_5.parameters(),lr=0.001)\n",
        "scheduler = lr_scheduler.LinearLR(opt1, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
        "net_5 = net_5.cuda()\n",
        "net_5.train()\n",
        "bs = 500\n",
        "for epoch in range(epochs):\n",
        "    for ct in range(0,len(X),bs):\n",
        "        x = data[ct:bs+ct].detach().cuda() \n",
        "\n",
        "        opt1.zero_grad()\n",
        "        y_hat = net_5(x).cuda() \n",
        "        f = py_kde(x,x,0.65)\n",
        "        f_der = py_kde_der(x,x,0.65)\n",
        "        loss = criterion(torch.squeeze(y_hat[0:,0:,0]),torch.squeeze(y[ct:bs+ct])).cuda()  +torch.linalg.norm(f_der/f.view(f.shape[0],1)+ net_5.loss_reg,dim=1)\n",
        "        loss.backward(torch.ones_like(loss), retain_graph=True)\n",
        "        opt1.step()\n",
        "\n",
        "    print(\"Epoch number:\",epoch,\"LR :\",opt1.param_groups[0][\"lr\"], \" Loss:\",torch.sum(loss)/bs, \"Reg Loss:\",torch.sum(torch.linalg.norm(torch.autograd.grad(f,x,torch.ones_like(f),allow_unused=True,create_graph=True)[0]/f.view(f.shape[0],1)+net_5.loss_reg,dim=1)/bs))\n",
        "    # if(epoch%5==4):\n",
        "    #     scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss(reduction= 'none')\n",
        "def my_loss(y_pred,y_train,reg_loss):\n",
        "    loss = criterion(y_pred,y_train) +reg_loss\n",
        "    return loss\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "net_10 = Net(10)\n",
        "import torch.optim.lr_scheduler as lr_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch number: 0 LR : 0.001  Loss: tensor(3.4346, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8708, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 1 LR : 0.001  Loss: tensor(3.3440, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8753, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 2 LR : 0.001  Loss: tensor(3.3359, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8759, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 3 LR : 0.001  Loss: tensor(3.3310, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 4 LR : 0.001  Loss: tensor(3.3230, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 5 LR : 0.001  Loss: tensor(3.3160, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 6 LR : 0.001  Loss: tensor(3.3111, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 7 LR : 0.001  Loss: tensor(3.3076, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 8 LR : 0.001  Loss: tensor(3.3041, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 9 LR : 0.001  Loss: tensor(3.3005, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 10 LR : 0.001  Loss: tensor(3.2976, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 11 LR : 0.001  Loss: tensor(3.2951, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 12 LR : 0.001  Loss: tensor(3.2932, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 13 LR : 0.001  Loss: tensor(3.2915, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 14 LR : 0.001  Loss: tensor(3.2901, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 15 LR : 0.001  Loss: tensor(3.2889, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 16 LR : 0.001  Loss: tensor(3.2880, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 17 LR : 0.001  Loss: tensor(3.2873, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 18 LR : 0.001  Loss: tensor(3.2867, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch number: 19 LR : 0.001  Loss: tensor(3.2862, device='cuda:0', grad_fn=<DivBackward0>) Reg Loss: tensor(2.8760, device='cuda:0', grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "data=X.cuda() \n",
        "epochs = 20\n",
        "y = Y.cuda()\n",
        "opt1 = torch.optim.Adam(net_10.parameters(),lr=0.001)\n",
        "scheduler = lr_scheduler.LinearLR(opt1, start_factor=1.0, end_factor=0.1, total_iters=10)\n",
        "net_10 = net_10.cuda()\n",
        "net_10.train()\n",
        "bs = 500\n",
        "for epoch in range(epochs):\n",
        "    for ct in range(0,len(X),bs):\n",
        "        x = data[ct:bs+ct].detach().cuda() \n",
        "\n",
        "        opt1.zero_grad()\n",
        "        y_hat = net_10(x).cuda() \n",
        "        f = py_kde(x,x,0.65)\n",
        "        f_der = py_kde_der(x,x,0.65)\n",
        "        loss = criterion(torch.squeeze(y_hat[0:,0:,0]),torch.squeeze(y[ct:bs+ct])).cuda()  +torch.linalg.norm(f_der/f.view(f.shape[0],1)+ net_10.loss_reg,dim=1)\n",
        "        loss.backward(torch.ones_like(loss), retain_graph=True)\n",
        "        opt1.step()\n",
        "\n",
        "    print(\"Epoch number:\",epoch,\"LR :\",opt1.param_groups[0][\"lr\"], \" Loss:\",torch.sum(loss)/bs, \"Reg Loss:\",torch.sum(torch.linalg.norm(torch.autograd.grad(f,x,torch.ones_like(f),allow_unused=True,create_graph=True)[0]/f.view(f.shape[0],1)+net_10.loss_reg,dim=1)/bs))\n",
        "    # if(epoch%5==4):\n",
        "    #     scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTest set:Loss: 0.592665 Acc: 78.400000 \n",
            "\tTest set:Loss: 0.643267 Acc: 79.900000 \n",
            "\tTest set:Loss: 0.573483 Acc: 78.250000 \n",
            "\tTest set:Loss: 0.615782 Acc: 79.600000 \n",
            "\tTest set:Loss: 0.617895 Acc: 78.050000 \n",
            "\tTest set:Loss: 0.626925 Acc: 79.250000 \n",
            "\tTest set:Loss: 0.668313 Acc: 66.700000 \n",
            "\tTest set:Loss: 0.526511 Acc: 80.250000 \n",
            "\tTest set:Loss: 0.608136 Acc: 80.150000 \n",
            "\tTest set:Loss: 0.563048 Acc: 77.900000 \n",
            "\tTest set:Loss: 0.630606 Acc: 79.900000 \n",
            "\tTest set:Loss: 0.552613 Acc: 80.850000 \n",
            "\tTest set:Loss: 0.576246 Acc: 78.950000 \n",
            "\tTest set:Loss: 0.588518 Acc: 79.700000 \n",
            "\tTest set:Loss: 0.547800 Acc: 78.450000 \n",
            "\tTest set:Loss: 0.546817 Acc: 80.050000 \n",
            "\tTest set:Loss: 0.577356 Acc: 78.700000 \n",
            "\tTest set:Loss: 0.584229 Acc: 80.200000 \n",
            "\tTest set:Loss: 0.580085 Acc: 79.600000 \n",
            "\tTest set:Loss: 0.564041 Acc: 78.750000 \n",
            "\tTest set:Loss: 0.569247 Acc: 80.300000 \n",
            "\tTest set:Loss: 0.542650 Acc: 78.300000 \n",
            "\tTest set:Loss: 0.534359 Acc: 80.100000 \n",
            "\tTest set:Loss: 0.609126 Acc: 79.250000 \n",
            "\tTest set:Loss: 0.539027 Acc: 78.150000 \n",
            "\tTest set:Loss: 0.556073 Acc: 80.150000 \n",
            "\tTest set:Loss: 0.574141 Acc: 78.600000 \n",
            "\tTest set:Loss: 0.547255 Acc: 79.600000 \n",
            "\tTest set:Loss: 0.525119 Acc: 80.300000 \n",
            "\tTest set:Loss: 0.588512 Acc: 78.700000 \n",
            "\tTest set:Loss: 0.572014 Acc: 79.100000 \n",
            "\tTest set:Loss: 0.546868 Acc: 78.950000 \n",
            "\tTest set:Loss: 0.615209 Acc: 79.450000 \n",
            "\tTest set:Loss: 0.527769 Acc: 79.900000 \n",
            "\tTest set:Loss: 0.550763 Acc: 80.100000 \n",
            "\tTest set:Loss: 0.520390 Acc: 78.250000 \n",
            "\tTest set:Loss: 0.573783 Acc: 78.950000 \n",
            "\tTest set:Loss: 0.498688 Acc: 80.850000 \n",
            "\tTest set:Loss: 0.542042 Acc: 78.750000 \n",
            "\tTest set:Loss: 0.493032 Acc: 80.700000 \n",
            "\tTest set:Loss: 0.529687 Acc: 79.250000 \n",
            "\tTest set:Loss: 0.565371 Acc: 78.450000 \n",
            "\tTest set:Loss: 0.610866 Acc: 78.550000 \n",
            "\tTest set:Loss: 0.525344 Acc: 79.100000 \n",
            "\tTest set:Loss: 0.511539 Acc: 79.100000 \n",
            "\tTest set:Loss: 0.514319 Acc: 78.900000 \n",
            "\tTest set:Loss: 0.594263 Acc: 80.200000 \n",
            "\tTest set:Loss: 0.608697 Acc: 80.100000 \n",
            "\tTest set:Loss: 0.520816 Acc: 79.200000 \n",
            "\tTest set:Loss: 0.546796 Acc: 80.000000 \n",
            "\tTest set:Loss: 0.524545 Acc: 78.450000 \n",
            "\tTest set:Loss: 0.524179 Acc: 80.500000 \n",
            "\tTest set:Loss: 0.509648 Acc: 79.500000 \n",
            "\tTest set:Loss: 0.522312 Acc: 79.600000 \n",
            "\tTest set:Loss: 0.529326 Acc: 80.250000 \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import dcMinMaxFunctions as dc\n",
        "# import dcor\n",
        "from scipy.misc import derivative\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "def normalize(x):\n",
        "    x_normed = x / x.max(0, keepdim=True)[0]\n",
        "    return x_normed\n",
        "\n",
        "\n",
        "\n",
        "def OHE(x):\n",
        "    dim = max(x)\n",
        "    y = np.zeros((len(x),dim+1))\n",
        "    for i in range(len(x)):\n",
        "        y[i][x[i]] = 1\n",
        "    return(y)\n",
        "#write a script to load data from data folder and train model\n",
        "\n",
        "\n",
        "def gau_ker(u):\n",
        "    return torch.pow(2*torch.tensor(torch.pi),u.shape[1]/(-2))*torch.exp(torch.bmm(u.view(u.shape[0], 1, u.shape[1]), u.view(u.shape[0],  u.shape[1],1))/(-2))\n",
        "def py_kde(x,X_t,h):\n",
        "    norm = (X_t.shape[0]*(h**x.shape[1]))\n",
        "    prob = torch.zeros(x.shape[0]).to(x.device) \n",
        "    for i in range(len(X_t)):\n",
        "        prob+= torch.squeeze(gau_ker((x - X_t[i])/h))/norm\n",
        "    return(prob)\n",
        "def py_kde_der(p_x,x):\n",
        "    # x.requires_grad = True\n",
        "    # p_x = py_kde(x,X_t,h)\n",
        "    return (torch.autograd.grad(p_x,x,torch.ones_like(p_x),allow_unused=True,create_graph=True)[0])\n",
        "\n",
        "# def accuracy(net,X_test,Y_test):\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#         outputs = net(X_test)\n",
        "#         predicted = (outputs > 0.5).float()\n",
        "#         total += Y_test.size(0)\n",
        "#         correct += (predicted == Y_test).sum().item()\n",
        "#     return(100 * correct / total)\n",
        "\n",
        "def accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def train_model(net,trainloader,optimizer,epochs,rate = 10,device= torch.device('cpu'),print_cond = True,privacy_engine = None):\n",
        "    criterion = nn.BCELoss(reduction= 'none')\n",
        "    counter =0\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "    \n",
        "        # data = data.to(device)\n",
        "        net = net.to(device)\n",
        "        with BatchMemoryManager(\n",
        "        data_loader=trainloader, \n",
        "        max_physical_batch_size=1000, \n",
        "        optimizer=optimizer\n",
        "    ) as memory_safe_data_loader:\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                \n",
        "                inputs = data[0].to(device)\n",
        "                labels = data[1].to(device)\n",
        "            \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs,labels)\n",
        "                loss.backward(torch.ones_like(loss))\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                # print(loss.sum().shape)\n",
        "                running_loss += loss.sum()\n",
        "                counter+=1\n",
        "        DELTA = 1e-4\n",
        "        if (epoch+1) % rate == 0:\n",
        "            if(privacy_engine != None):\n",
        "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
        "            else:\n",
        "                epsilon = 0\n",
        "            print(\n",
        "                f\"\\tTrain Epoch: {epoch} \\t\"\n",
        "                f\"Loss: {(running_loss/counter):.6f} \"\n",
        "                # f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
        "                f\"(Îµ = {epsilon:.2f}, Î´ = {DELTA})\"\n",
        "                \n",
        "                )\n",
        "            counter = 0\n",
        "            # if i % 100 == 99:    # print every 2000 mini-batches\n",
        "        # if(epoch%rate==rate-1):\n",
        "        #     if(print_cond):\n",
        "        #         print('[%d, %5d] loss: %.10f' %\n",
        "        #                 (epoch + 1,0, running_loss / 100))\n",
        "        #         running_loss = 0.0\n",
        "            # if(privacy_engine != None):\n",
        "                \n",
        "            #     eps_val.append(privacy_engine.get_epsilon(delta))\n",
        "            #     acc.append(accuracy(net,X_test,Y_test))\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "\n",
        "def train(model, train_loader, optimizer, epoch, device,privacy_engine = None):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    losses = []\n",
        "    top1_acc = []\n",
        "    \n",
        "    with BatchMemoryManager(\n",
        "        data_loader=train_loader, \n",
        "        max_physical_batch_size=1000, \n",
        "        optimizer=optimizer\n",
        "    ) as memory_safe_data_loader:\n",
        "\n",
        "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
        "            preds = output.detach().cpu().numpy()\n",
        "            labels = target.detach().cpu().numpy()\n",
        "            # print(preds.shape,labels.shape )\n",
        "            # measure accuracy and record loss\n",
        "            acc = accuracy(preds, labels)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            # top1_acc.append(acc)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            DELTA = 1e-4\n",
        "    # if (+1) % 10 == 0:\n",
        "    #     epsilon = privacy_engine.get_epsilon(DELTA)\n",
        "    #     print(\n",
        "    #         f\"\\tTrain Epoch: {epoch} \\t\"\n",
        "    #         f\"Loss: {np.mean(losses):.6f} \"\n",
        "    #         f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
        "    #         f\"(Îµ = {epsilon:.2f}, Î´ = {DELTA})\"\n",
        "    #     )\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    criterion = nn.BCELoss()\n",
        "    losses = []\n",
        "    top1_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, target in test_loader:\n",
        "            images = images.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "            preds = output.detach().cpu().numpy() > 0.5\n",
        "            labels = target.detach().cpu().numpy()\n",
        "            acc = accuracy(preds, labels)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            top1_acc.append(acc)\n",
        "\n",
        "    top1_avg = np.mean(top1_acc)\n",
        "\n",
        "    print(\n",
        "        f\"\\tTest set:\"\n",
        "        f\"Loss: {np.mean(losses):.6f} \"\n",
        "        f\"Acc: {top1_avg * 100:.6f} \"\n",
        "    )\n",
        "    return np.mean(top1_acc)\n",
        "\n",
        "def load_data(path):\n",
        "    df=pd.read_csv(\"data/Churn_Modelling.csv\")\n",
        "    X = df.loc[:, df.columns != 'Exited'].replace(dict(yes=True, no=False))\n",
        "    Y = df.loc[:, ['Exited']].replace(dict(yes=True, no=False))\n",
        "    categorical_columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
        "    numerical_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    outputs = ['Exited']\n",
        "    for category in categorical_columns:\n",
        "        df[category] = df[category].astype('category')\n",
        "    geo = OHE(df['Geography'].cat.codes.values)\n",
        "    gen =  np.asarray(df['Gender'].cat.codes.values)\n",
        "    hcc =  np.asarray(df['HasCrCard'].cat.codes.values)\n",
        "    iam =  np.asarray(df['IsActiveMember'].cat.codes.values)\n",
        "\n",
        "    categorical_data = np.stack(( gen, hcc, iam), axis=1)\n",
        "    # categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
        "    numerical_data = np.stack([df[col].values for col in numerical_columns], 1)\n",
        "    # numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
        "    X = np.concatenate((numerical_data, categorical_data,geo), axis=1)\n",
        "    Y = df[outputs].values\n",
        "    # outputs = torch.tensor(df[outputs].values).flatten()\n",
        "    X = torch.Tensor(X)\n",
        "    Y = torch.Tensor(Y)\n",
        "    X = normalize(X)\n",
        "    return X,Y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    accs =[]\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    \n",
        "    # print(ModuleValidator.validate(model2, strict=False))\n",
        "    eps_list =np.arange(0.5,6,0.1)\n",
        "    for target_eps in eps_list:\n",
        "        X,Y = load_data(\"data/Churn_Modelling.csv\")\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "        \n",
        "        trainer = torch.utils.data.TensorDataset(X_train,Y_train)\n",
        "        tester  = torch.utils.data.TensorDataset(X_test,Y_test)\n",
        "\n",
        "        trainloader = torch.utils.data.DataLoader(trainer, batch_size=1000,\n",
        "                                                shuffle=True, num_workers=2)\n",
        "        testloader = torch.utils.data.DataLoader(tester, batch_size=1000,\n",
        "                                                shuffle=False, num_workers=2)   \n",
        "    \n",
        "        \n",
        "        \n",
        "        from opacus.validators import ModuleValidator\n",
        "\n",
        "        \n",
        "    \n",
        "        privacy_engine = PrivacyEngine()\n",
        "        \n",
        "        # model2 = nn.Sequential(\n",
        "        #     nn.Linear(12, 32),\n",
        "        #     nn.ReLU(),\n",
        "        #     # nn.Linear(48, 32),\n",
        "        #     # nn.ReLU(),\n",
        "        #     nn.Linear(32, 1),\n",
        "        #     nn.Sigmoid(\n",
        "\n",
        "        #     )\n",
        "        # )\n",
        "        # optim2 = torch.optim.Adam(model2.parameters(),lr=0.01,weight_decay=1e-4)\n",
        "\n",
        "        # train_model(model2,trainloader,optim2,100,10,device=torch.device('cuda'))\n",
        "        # print(accuracy(model2,X_test.to('cuda'),Y_test.to('cuda')))\n",
        "        # print(accuracy(model2,X_train.to('cuda'),Y_train.to('cuda')))\n",
        "        # model2= nn.Sequential(\n",
        "        #     nn.Linear(12, 32),\n",
        "        #     nn.ReLU(),\n",
        "        #     # nn.Linear(48, 32),\n",
        "        #     # nn.ReLU(),\n",
        "        #     nn.Linear(32, 1),\n",
        "        #     nn.Sigmoid(\n",
        "\n",
        "        #     )\n",
        "        # )\n",
        "        \n",
        "        \n",
        "        model2= nn.Sequential(\n",
        "            nn.Linear(12, 32),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(48, 32),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid(\n",
        "\n",
        "            )\n",
        "        )\n",
        "        # print(test(model,testloader,torch.device('cuda')))\n",
        "        # model.train()\n",
        "        optim = torch.optim.Adam(model2.parameters(),lr=0.01,weight_decay=1e-4)\n",
        "        model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "            \n",
        "            module=model2,\n",
        "            optimizer=optim,\n",
        "            data_loader=trainloader,\n",
        "            epochs=1000,\n",
        "            target_epsilon=target_eps,\n",
        "            target_delta= 1e-4,\n",
        "            max_grad_norm=3.0,\n",
        "        )\n",
        "\n",
        "        # train_model(model,train_loader,optimizer,100,10,device=torch.device('cuda'),privacy_engine=privacy_engine)\n",
        "        train(model,train_loader,optimizer,1000,torch.device('cuda'),privacy_engine=privacy_engine)\n",
        "        # # print(accuracy(model,X_test.to('cuda'),Y_test.to('cuda')))\n",
        "        # # print(accuracy(model,X_train.to('cuda'),Y_train.to('cuda')))\n",
        "        accs.append(test(model,testloader,torch.device('cuda')))\n",
        "        # print(target_eps)\n",
        "        del(model)\n",
        "        del(privacy_engine)\n",
        "        del(optimizer)\n",
        "        del(train_loader)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    x = eps_list\n",
        "    y = accs\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.xlabel('X-axis')\n",
        "    plt.ylabel('Y-axis')\n",
        "    plt.title('Plotting x and y')\n",
        "    plt.show()   \n",
        "        # del(test)\n",
        "# Main body of code. Other functions and class methods are called from main.\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=X\n",
        "\n",
        "\n",
        "losses= torch.zeros(X.shape[0])\n",
        "bs = 1000\n",
        "\n",
        "for ct in range(0,len(X),bs):\n",
        "    x = data[ct:bs+ct].detach()\n",
        "    x_hat = autoencoder1(x)\n",
        "    f = py_kde(x,x,0.5)\n",
        "    loss =torch.linalg.norm(torch.autograd.grad(f,x,torch.ones_like(f),allow_unused=True,create_graph=True)[0]/f.view(f.shape[0],1)+autoencoder1.loss_reg,dim=1)\n",
        "    losses[ct:bs+ct] =loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.7565365433692932\n"
          ]
        }
      ],
      "source": [
        "# with torch.no_grad():\n",
        "y_pred = autoencoder1(X)\n",
        " \n",
        "accuracy = (y_pred.round() == Y).float().mean()\n",
        "print(f\"Accuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6493816315762113"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n=1000\n",
        "d =12\n",
        "n**(-1./(d+4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9828)"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(losses<3).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        " \n",
        "# Creating dataset\n",
        "a = losses.detach()\n",
        " \n",
        "# Creating histogram\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(a, bins = np.arange(0,4,0.1))\n",
        " \n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "o = autoencoder1(X_train.detach())\n",
        "X_emb_train = torch.squeeze(autoencoder1.y).detach()\n",
        "o = autoencoder1(X_test.detach())\n",
        "X_emb_test = torch.squeeze(autoencoder1.y).detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.8335000276565552\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# o = autoencoder1(X)\n",
        "# X_embs = torch.squeeze(autoencoder1.y.detach())\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(12, 48),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(48, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1),\n",
        "    nn.Sigmoid(\n",
        "\n",
        "    )\n",
        ")\n",
        "loss_fn = nn.BCELoss()  # binary cross entropy\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "n_epochs = 1000\n",
        "batch_size = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X_emb_train), batch_size):\n",
        "        Xbatch = X_emb_train[i:i+batch_size]\n",
        "        y_pred = model(Xbatch)\n",
        "        ybatch = Y_train[i:i+batch_size]\n",
        "        loss = loss_fn(y_pred, ybatch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    #     print(loss)\n",
        "    # print(f'Finished epoch {epoch}, latest loss {loss}')\n",
        "# compute accuracy (no_grad is optional)\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_emb_test)\n",
        " \n",
        "accuracy = (y_pred.round() == Y_test).float().mean()\n",
        "print(f\"Accuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.871999979019165\n"
          ]
        }
      ],
      "source": [
        "model1 = nn.Sequential(\n",
        "    nn.Linear(12, 48),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(48, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1),\n",
        "    nn.Sigmoid(\n",
        "\n",
        "    )\n",
        ")\n",
        "loss_fn = nn.BCELoss()  # binary cross entropy\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
        "n_epochs = 1000\n",
        "batch_size = 1000\n",
        " \n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        Xbatch = X_train[i:i+batch_size]\n",
        "        y_pred = model1(Xbatch)\n",
        "        ybatch = Y_train[i:i+batch_size]\n",
        "        loss = loss_fn(y_pred, ybatch)\n",
        "        optimizer1.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model1(X_test)\n",
        " \n",
        "accuracy = (y_pred.round() == Y_test).float().mean()\n",
        "print(f\"Accuracy {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
