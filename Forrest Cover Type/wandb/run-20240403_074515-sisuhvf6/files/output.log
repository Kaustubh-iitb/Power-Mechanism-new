tensor(464809)
4096
Traceback (most recent call last):
  File "/home/surajracha/ChatLLM/DataGen/Data/Gemini/Data2/Power-Mechanism-new/Forrest Cover Type/cov_tester_2.py", line 177, in <module>
    main(data_path=data_path,batch_size=batch_size,num_epochs=num_epochs,learning_rate=learning_rate,model_path=model_path)
  File "/home/surajracha/ChatLLM/DataGen/Data/Gemini/Data2/Power-Mechanism-new/Forrest Cover Type/cov_tester_2.py", line 170, in main
    train_emb(model, train_emb_loader, criterion, optimizer, num_epochs=num_epochs,device=device,test_loader = test_emb_loader,test_total_loader = None)
  File "/home/surajracha/ChatLLM/DataGen/Data/Gemini/Data2/Power-Mechanism-new/Forrest Cover Type/cov_help.py", line 596, in train_emb
    for i, data in enumerate(train_loader, 0):
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 439, in __iter__
    return self._get_iterator()
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 387, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1085, in __init__
    self._reset(loader, first_iter=True)
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1118, in _reset
    self._try_put_index()
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1352, in _try_put_index
    index = self._next_index()
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 621, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 280, in __iter__
    batch = [next(sampler_iter) for _ in range(self.batch_size)]
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 280, in <listcomp>
    batch = [next(sampler_iter) for _ in range(self.batch_size)]
  File "/home/surajracha/miniconda3/envs/chatllm/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 167, in __iter__
    yield from torch.randperm(n, generator=generator).tolist()
KeyboardInterrupt