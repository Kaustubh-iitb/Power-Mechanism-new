{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Split the DataFrame df into features (X) and target (y)\n",
    "data=pd.read_csv('data/training.csv')\n",
    "df_data = data.drop(columns=['EventId','Weight'])\n",
    "X = df_data.drop(columns=['Label'])  # Features\n",
    "\n",
    "X = np.asarray(pd.get_dummies(X, columns=['PRI_jet_num'], prefix='PRI_jet_num').values, dtype = np.float32)\n",
    "X = X/np.linalg.norm(X, axis=1).max()\n",
    "y = df_data['Label'].values  # Target\n",
    "y = np.where(y == 's', 1, 0)\n",
    "y = np.asarray(y, dtype = np.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert X_train and X_test to tensors\n",
    "x_train_tensor = torch.tensor(X_train)\n",
    "x_test_tensor = torch.tensor(X_test)\n",
    "\n",
    "# Convert y_train and y_test to tensors\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "# x_train_tensor = normalize2(x_train_tensor)\n",
    "# x_test_tensor = normalize2(x_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "** Formed Tensors and starting model training** \n",
      " \n",
      " \n",
      "tensor(1.6581) tensor(0.9698)\n",
      "tensor(1.5434) tensor(0.8588)\n",
      "tensor(1.5184) tensor(0.8377)\n",
      "tensor(1.4996) tensor(0.8230)\n",
      "tensor(1.4698) tensor(0.7937)\n",
      "tensor(1.4652) tensor(0.7915)\n",
      "tensor(1.4526) tensor(0.7852)\n",
      "tensor(1.4516) tensor(0.7839)\n",
      "tensor(1.4383) tensor(0.7763)\n",
      "tensor(1.4285) tensor(0.7689)\n",
      "tensor(1.4332) tensor(0.7752)\n",
      "tensor(1.4260) tensor(0.7676)\n",
      "tensor(1.4240) tensor(0.7713)\n",
      "tensor(1.4252) tensor(0.7761)\n",
      "tensor(1.4149) tensor(0.7697)\n",
      "tensor(1.4045) tensor(0.7650)\n",
      "tensor(1.4206) tensor(0.7728)\n",
      "tensor(1.4030) tensor(0.7650)\n",
      "tensor(1.4078) tensor(0.7660)\n",
      "tensor(1.4081) tensor(0.7756)\n",
      "tensor(1.3994) tensor(0.7636)\n",
      "tensor(1.4095) tensor(0.7728)\n",
      "tensor(1.3955) tensor(0.7690)\n",
      "tensor(1.4025) tensor(0.7696)\n",
      "tensor(1.3898) tensor(0.7640)\n",
      "tensor(1.4016) tensor(0.7689)\n",
      "tensor(1.3921) tensor(0.7585)\n",
      "tensor(1.3826) tensor(0.7633)\n",
      "tensor(1.3985) tensor(0.7662)\n",
      "tensor(1.3994) tensor(0.7709)\n",
      "tensor(1.3900) tensor(0.7587)\n",
      "tensor(1.3950) tensor(0.7624)\n",
      "tensor(1.3973) tensor(0.7585)\n",
      "tensor(1.3849) tensor(0.7581)\n",
      "tensor(1.3894) tensor(0.7534)\n",
      "tensor(1.3932) tensor(0.7676)\n",
      "tensor(1.3832) tensor(0.7501)\n",
      "tensor(1.3923) tensor(0.7611)\n",
      "tensor(1.3815) tensor(0.7622)\n",
      "tensor(1.3980) tensor(0.7604)\n",
      "tensor(1.3867) tensor(0.7569)\n",
      "tensor(1.3965) tensor(0.7648)\n",
      "tensor(1.3897) tensor(0.7631)\n",
      "tensor(1.3843) tensor(0.7626)\n",
      "tensor(1.3901) tensor(0.7647)\n",
      "tensor(1.3813) tensor(0.7625)\n",
      "tensor(1.3758) tensor(0.7543)\n",
      "tensor(1.3790) tensor(0.7545)\n",
      "Test Accuracy:  tensor(0.6814)\n",
      "tensor(0.6814)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n** Formed Tensors and starting model training** \\n \\n \")\n",
    "net = Net_new(1,device = torch.device('cuda:3'))\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(x_train_tensor, y_train_tensor)), batch_size=4096, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "net = net.to(device=torch.device('cuda:3'))\n",
    "\n",
    "train_model_priv(net,trainloader,x_test_tensor,y_test_tensor,optimizer,1,0.8,device= torch.device('cuda:3'),print_cond = True,only_reg_flag=0,lr_schedular =None,lambda_loss=1)\n",
    "outputs = net(x_test_tensor)\n",
    "print(((outputs>0.5).squeeze().cpu() == y_test_tensor.squeeze()).sum()/(len(y_test_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.2395e-02,  3.3172e-03,  1.8058e-02,  4.8197e-02,  4.3333e-04,\n",
       "         6.0725e-02,  1.2431e-04,  2.8626e-04,  1.6094e-03,  8.5882e-02,\n",
       "         2.2279e-04,  2.5934e-04,  7.3754e-05,  1.4200e-02,  9.2356e-05,\n",
       "         2.2454e-04,  1.4453e-02, -4.6178e-05,  4.7491e-04,  2.5048e-02,\n",
       "         4.3661e-04,  9.9252e-02,  4.5627e-02, -5.5589e-05, -2.4643e-04,\n",
       "         1.1603e-02, -4.8892e-04, -5.4013e-04,  5.7230e-02,  0.0000e+00,\n",
       "         0.0000e+00,  2.1885e-04,  0.0000e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3266e-02,  5.4836e-03,  1.6235e-02,  4.0966e-03, -1.7044e-01,\n",
       "        -1.7044e-01, -1.7044e-01,  4.5211e-04,  4.0966e-03,  1.3821e-02,\n",
       "         8.5133e-05, -1.6651e-04, -1.7044e-01,  9.2203e-03, -5.1182e-06,\n",
       "        -2.5011e-04,  4.6011e-03, -2.7928e-04,  1.0936e-04,  6.9328e-03,\n",
       "         2.8235e-04,  2.9274e-02, -1.7044e-01, -1.7044e-01, -1.7044e-01,\n",
       "        -1.7044e-01, -1.7044e-01, -1.7044e-01,  0.0000e+00,  1.7061e-04,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ** Creating embeddings ** \n",
      " \n",
      "  200000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n ** Creating embeddings ** \\n \\n \",len(y_train_tensor))\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(x_train_tensor, y_train_tensor)), batch_size=4096, shuffle=False)\n",
    "X_emb_train, losses_train = create_model_embs2(net,trainloader,device= torch.device('cuda:3'),l=len(y_train_tensor),h=0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "# x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(X_test)\n",
    "# x_test_tensor = normalize2(x_test_tensor)\n",
    "\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "testloader = torch.utils.data.DataLoader(list(zip(x_test_tensor, y_test_tensor)), batch_size=4096, shuffle=False)\n",
    "X_emb_test, losses_test = create_model_embs2(net,testloader,device= torch.device('cuda:3'),l=len(y_test_tensor),h=0.8)\n",
    "losses_train,indices = torch.sort(losses_train)\n",
    "\n",
    "# x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "# x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "set_eps = 1\n",
    "ind = (losses_train < set_eps).sum()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "X_emb_train_priv = X_emb_train[indices][:ind]\n",
    "Y_train = y_train_tensor[indices][:ind]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73322"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_emb_train_priv, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_emb_test)\n",
    "(predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ** Starting final training ** \n",
      " \n",
      " \n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6592)\n",
      "Test Accuracy:  tensor(0.6677)\n",
      "Test Accuracy:  tensor(0.6919)\n",
      "Test Accuracy:  tensor(0.7068)\n",
      "Test Accuracy:  tensor(0.7095)\n",
      "Test Accuracy:  tensor(0.7101)\n",
      "Test Accuracy:  tensor(0.7143)\n",
      "Test Accuracy:  tensor(0.7169)\n",
      "Test Accuracy:  tensor(0.7182)\n",
      "Test Accuracy:  tensor(0.7220)\n",
      "Test Accuracy:  tensor(0.7239)\n",
      "Test Accuracy:  tensor(0.7235)\n",
      "Test Accuracy:  tensor(0.7237)\n",
      "Test Accuracy:  tensor(0.7177)\n",
      "Test Accuracy:  tensor(0.7222)\n",
      "Test Accuracy:  tensor(0.7282)\n",
      "Test Accuracy:  tensor(0.7313)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(33, 64),  # Input layer with 100 input features and 64 output features\n",
    "    nn.ReLU(),  # Activation function\n",
    "    nn.Linear(64, 128),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(128,32),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(),# Activation function\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()# Output layer with 32 input features and 10 output features\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.00001)\n",
    "trainloader_priv = torch.utils.data.DataLoader(list(zip(X_emb_train_priv, Y_train)), batch_size=512, shuffle=True)\n",
    "print(\"\\n \\n ** Starting final training ** \\n \\n \")\n",
    "train_emb(model,trainloader_priv,X_emb_test,y_test_tensor,nn.BCELoss(),optimizer,num_epochs,device=torch.device('cuda:0'),test_total_loader = None,max_steps =10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/ganesh/racha_suraj/miniconda3/envs/dpo/lib/python3.12/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/raid/ganesh/racha_suraj/miniconda3/envs/dpo/lib/python3.12/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/raid/ganesh/racha_suraj/miniconda3/envs/dpo/lib/python3.12/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6613)\n",
      "Test Accuracy:  tensor(0.6615)\n",
      "Test Accuracy:  tensor(0.6639)\n",
      "Test Accuracy:  tensor(0.6664)\n",
      "Test Accuracy:  tensor(0.6691)\n",
      "Test Accuracy:  tensor(0.6717)\n",
      "Test Accuracy:  tensor(0.6760)\n",
      "Test Accuracy:  tensor(0.6786)\n",
      "Test Accuracy:  tensor(0.6812)\n",
      "Test Accuracy:  tensor(0.6839)\n",
      "Test Accuracy:  tensor(0.6866)\n",
      "Test Accuracy:  tensor(0.6884)\n",
      "Test Accuracy:  tensor(0.6904)\n",
      "Test Accuracy:  tensor(0.6912)\n",
      "Test Accuracy:  tensor(0.6917)\n",
      "Test Accuracy:  tensor(0.6926)\n",
      "Test Accuracy:  tensor(0.6930)\n",
      "Test Accuracy:  tensor(0.6933)\n",
      "Test Accuracy:  tensor(0.6935)\n",
      "Test Accuracy:  tensor(0.6937)\n",
      "Test Accuracy:  tensor(0.6940)\n",
      "Test Accuracy:  tensor(0.6943)\n",
      "Test Accuracy:  tensor(0.6944)\n",
      "Test Accuracy:  tensor(0.6945)\n",
      "Test Accuracy:  tensor(0.6948)\n",
      "Test Accuracy:  tensor(0.6948)\n",
      "Test Accuracy:  tensor(0.6949)\n",
      "Test Accuracy:  tensor(0.6949)\n",
      "Test Accuracy:  tensor(0.6951)\n",
      "Test Accuracy:  tensor(0.6952)\n",
      "Test Accuracy:  tensor(0.6952)\n",
      "Test Accuracy:  tensor(0.6953)\n",
      "Test Accuracy:  tensor(0.6953)\n",
      "Test Accuracy:  tensor(0.6956)\n",
      "Test Accuracy:  tensor(0.6956)\n",
      "Test Accuracy:  tensor(0.6957)\n",
      "Test Accuracy:  tensor(0.6957)\n",
      "Test Accuracy:  tensor(0.6957)\n",
      "Test Accuracy:  tensor(0.6958)\n",
      "Test Accuracy:  tensor(0.6958)\n",
      "Test Accuracy:  tensor(0.6959)\n",
      "Test Accuracy:  tensor(0.6958)\n",
      "Test Accuracy:  tensor(0.6960)\n"
     ]
    }
   ],
   "source": [
    "input_size = 33\n",
    "num_epochs = 50\n",
    "# model = LogisticRegression(input_size)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(33, 64),  # Input layer with 100 input features and 64 output features\n",
    "    nn.ReLU(),  # Activation function\n",
    "    nn.Linear(64, 128),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(128,32),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(),# Activation function\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()# Output layer with 32 input features and 10 output features\n",
    ")\n",
    "from opacus import PrivacyEngine\n",
    "privacy_engine = PrivacyEngine()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model2, optimizer2, data_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=trainloader,\n",
    "    target_epsilon=1,\n",
    "    target_delta =0.0001,\n",
    "    epochs = num_epochs,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "train_emb(model2,data_loader,x_test_tensor,y_test_tensor,nn.BCELoss(),optimizer2,num_epochs,device=torch.device('cuda:0'),max_steps =10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71584\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_emb_train_priv, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_emb_test)\n",
    "\n",
    "print(\"Accuracy:\", (predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83132"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_tensor)\n",
    "(predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83946"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_tensor)\n",
    "(predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
