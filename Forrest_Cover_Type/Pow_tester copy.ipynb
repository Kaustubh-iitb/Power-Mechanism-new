{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import dcMinMaxFunctions as dc\n",
    "# import dcor\n",
    "from scipy.misc import derivative\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from scipy import stats\n",
    "import wandb\n",
    "from cov_help import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_path = 'data/covtype.csv'\n",
    "norm =1\n",
    "X,Y = cov_data_loader(data_path,norm=norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "train_priv = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "test_priv = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "trainloader_priv = torch.utils.data.DataLoader(train_priv, batch_size=4096,\n",
    "                                          shuffle=True, num_workers=4, drop_last=True)\n",
    "testloader_priv = torch.utils.data.DataLoader(test_priv, batch_size=4096,\n",
    "                                          shuffle=False, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "net = Net_new(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cov_full_2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'Models/cov_full_2'\n",
    "model_path.replace('Models/','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from cov_help import *\n",
    "data_path = 'data/covtype.csv'\n",
    "norm =1\n",
    "X,Y = cov_data_loader(data_path,norm=norm)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_public =  X_train[::10]\n",
    "# X_private  = torch.load('Embeddings/cov_full/X_emb_test.pt')[0::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46481, 54])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_public.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net_new(1,device = torch.device(\"cuda:0\"))\n",
    "state_dict  = torch.load(\"Models/cov_non_priv_emb_512_100\")\n",
    "\n",
    "net.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:25<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "X_priv_real  = X_train[1::10]\n",
    "train_priv = torch.utils.data.TensorDataset(X_priv_real, Y_train[1::10])\n",
    "\n",
    "\n",
    "trainloader_priv = torch.utils.data.DataLoader(train_priv, batch_size=4096,\n",
    "                                    shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "X_emb_train,losses_train = create_model_embs2(net,trainloader_priv,device= torch.device(\"cuda\"),l=len(X_priv_real),h=0.82)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_private = X_emb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "Combined_dataset = torch.utils.data.TensorDataset(X_private,X_public)\n",
    "data_loader = torch.utils.data.DataLoader(Combined_dataset, batch_size=4096, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Batch [0/12], Discriminator Loss: 1.3876, Autoencoder Loss: 0.0065\n",
      "Epoch [1/10], Batch [0/12], Discriminator Loss: 1.2185, Autoencoder Loss: 0.0014\n",
      "Epoch [2/10], Batch [0/12], Discriminator Loss: 0.9313, Autoencoder Loss: 0.0010\n",
      "Epoch [3/10], Batch [0/12], Discriminator Loss: 0.5676, Autoencoder Loss: 0.0008\n",
      "Epoch [4/10], Batch [0/12], Discriminator Loss: 0.2750, Autoencoder Loss: 0.0007\n",
      "Epoch [5/10], Batch [0/12], Discriminator Loss: 0.1083, Autoencoder Loss: 0.0004\n",
      "Epoch [6/10], Batch [0/12], Discriminator Loss: 0.0394, Autoencoder Loss: 0.0003\n",
      "Epoch [7/10], Batch [0/12], Discriminator Loss: 0.0170, Autoencoder Loss: 0.0003\n",
      "Epoch [8/10], Batch [0/12], Discriminator Loss: 0.0093, Autoencoder Loss: 0.0003\n",
      "Epoch [9/10], Batch [0/12], Discriminator Loss: 0.0060, Autoencoder Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the generator model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Define the layers of the encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(54, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 54)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(54, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 54)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass of the generator\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(54, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # Define the layers of the discriminator\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass of the discriminator\n",
    "        z = self.model(x)\n",
    "        return z\n",
    "\n",
    "# Initialize the generator and discriminator models\n",
    "ae = Autoencoder()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Define the loss function and optimizer for the generator and discriminator\n",
    "loss_function_disc = nn.BCELoss()\n",
    "loss_function_ae = nn.MSELoss()\n",
    "ae_optimizer = optim.Adam(ae.parameters(), lr=0.001)\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (private_data, public_data) in enumerate(data_loader):\n",
    "        batch_size = public_data.size(0)\n",
    "\n",
    "        # Train the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        public_labels = torch.ones(batch_size, 1)\n",
    "        private_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "        # Forward pass real data through discriminator\n",
    "        private_output = discriminator(private_data)\n",
    "        private_loss = loss_function_disc(private_output, private_labels)\n",
    "\n",
    "        # Generate fake data using the generator\n",
    "        # z = torch.randn(batch_size, latent_dim)\n",
    "        public_embedding = ae.encoder(public_data)\n",
    "        public_data_rec = ae.decoder(public_embedding)\n",
    "\n",
    "        # Forward pass fake data through discriminator\n",
    "        public_output = discriminator(public_embedding.detach())\n",
    "        public_loss = loss_function_disc(public_output, public_labels)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        discriminator_loss = public_loss + private_loss\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        # Train the generator\n",
    "        ae.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Forward pass fake data through discriminator\n",
    "        \n",
    "        ae_loss = loss_function_ae(public_data_rec, public_data)\n",
    "\n",
    "        ae_loss.backward()\n",
    "        ae_optimizer.step()\n",
    "\n",
    "        # Print the loss for every few batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(data_loader)}], \"\n",
    "                  f\"Discriminator Loss: {discriminator_loss.item():.4f}, \"\n",
    "                  f\"Autoencoder Loss: {ae_loss.item():.4f}\")\n",
    "\n",
    "# Save the trained generator and discriminator models\n",
    "# torch.save(generator.state_dict(), 'generator.pth')\n",
    "# torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
    "# X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x1 = ae.decoder(X_private) \n",
    "x2 = X_priv_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578848931918251\n"
     ]
    }
   ],
   "source": [
    "x1_np = x1.detach().numpy()\n",
    "x2_np = x2.detach().numpy()\n",
    "total = 0 \n",
    "for i in range(len(x1_np)):\n",
    "    correlation = np.corrcoef(x1_np[i], x2_np[i])[0][1]\n",
    "    total += correlation\n",
    "print(total/len(x1_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/covtype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x2[0][-40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[0][-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3164, 0.0022, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.2667, 0.0086, 0.0005,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3355, 0.0234, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.3202, 0.0023, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3358, 0.0035, 0.0009,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3309, 0.0256, 0.0017,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0363)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(x2)):\n",
    "    sum+= (torch.argmax(torch.abs(x1[i][-40:])) == torch.argmax(x2[i][-40:]))\n",
    "sum/len(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1686)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x3 = torch.zeros((x2.shape))\n",
    "for i in range(len(x2)):\n",
    "    x3[i][:13] = x1[i][:13]\n",
    "    x3[i][int(torch.argmax(x1[i][-40:]))] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_ae(x3, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
