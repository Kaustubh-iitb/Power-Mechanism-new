{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting data processing** \n",
      " \n",
      " \n",
      "48626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/adult.csv')\n",
    "# import os\n",
    "# default_n_threads = 1\n",
    "# os.environ['OPENBLAS_NUM_THREADS'] = f\"{default_n_threads}\"\n",
    "# os.environ['MKL_NUM_THREADS'] = f\"{default_n_threads}\"\n",
    "# os.environ['OMP_NUM_THREADS'] = f\"{default_n_threads}\"\n",
    "print(\"**Starting data processing** \\n \\n \")\n",
    "def convert_marital_status(status):\n",
    "    if status in ['Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse']:\n",
    "        return 'married'\n",
    "    elif status in ['Never-married', 'Separated', 'Widowed']:\n",
    "        return 'single'\n",
    "    else:\n",
    "        return 'divorced'\n",
    "\n",
    "df['marital-status'] = df['marital-status'].apply(convert_marital_status)\n",
    "\n",
    "df['native-country'] = df['native-country'].replace('Outlying-US(Guam-USVI-etc)' , 'US Minor Islands')\n",
    "\n",
    "df = df.drop(['capital-gain', 'capital-loss', 'fnlwgt'], axis=1)\n",
    "\n",
    "income_mapping = {'<=50K': 0, '>50K': 1}\n",
    "df['income'] = df['income'].map(income_mapping)\n",
    "\n",
    "\n",
    "def fill_missing_categorical(df, column):\n",
    "    df[column] = df[column].replace('?', np.nan)\n",
    "\n",
    "    if df[column].notna().all():\n",
    "        return df\n",
    "\n",
    "    known = df[df[column].notna()]\n",
    "    unknown = df[df[column].isna()]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    known[column] = le.fit_transform(known[column])\n",
    "    X_known = known.drop(column, axis=1)\n",
    "    y_known = known[column]\n",
    "\n",
    "    categorical_cols = X_known.select_dtypes(include=['object']).columns\n",
    "\n",
    "    le_cat = preprocessing.LabelEncoder()\n",
    "    X_known[categorical_cols] = X_known[categorical_cols].apply(lambda col: le_cat.fit_transform(col.astype(str)))\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_known, y_known)\n",
    "\n",
    "    X_unknown = unknown.drop(column, axis=1)\n",
    "\n",
    "    X_unknown[categorical_cols] = X_unknown[categorical_cols].apply(lambda col: le_cat.fit_transform(col.astype(str)))\n",
    "\n",
    "    unknown[column] = clf.predict(X_unknown)\n",
    "\n",
    "    df = pd.concat([known, unknown], axis=0)\n",
    "\n",
    "    df[column] = le.inverse_transform(df[column])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = fill_missing_categorical(df, 'native-country')\n",
    "df = fill_missing_categorical(df, 'occupation')\n",
    "df = fill_missing_categorical(df, 'workclass')\n",
    "\n",
    "Q1 = df['age'].quantile(0.25)\n",
    "Q3 = df['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df['age'] < Q1 - 1.5 * IQR) | (df['age'] > Q3 + 1.5 * IQR)]\n",
    "\n",
    "df.drop(outliers.index, inplace=True)\n",
    "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
    "df.drop(['age', 'hours-per-week'], axis=1, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "columns_to_keep = ['workclass', 'educational-num', 'marital-status', 'occupation', 'gender', 'native-country', 'income']\n",
    "Features = df[columns_to_keep]\n",
    "X= Features\n",
    "\n",
    "X = pd.get_dummies(X, columns=['workclass', 'marital-status', 'occupation', 'native-country'])\n",
    "\n",
    "X = X.drop(columns=['income'])\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X)\n",
    "X1 =X1/np.linalg.norm(X1,axis =1).max()\n",
    "\n",
    "X_fil = []\n",
    "Y_fil = []\n",
    "\n",
    "# ind  = y.values.sum()\n",
    "ind = len(y.values)\n",
    "counter = 0\n",
    "print(ind)\n",
    "for i in range(len(y.values)):\n",
    "    if y.values[i] == 0:\n",
    "        if counter < ind:\n",
    "            X_fil.append(X1[i])\n",
    "            Y_fil.append(y.values[i])\n",
    "            counter+=1\n",
    "    else:\n",
    "        X_fil.append(X1[i])\n",
    "        Y_fil.append(y.values[i])\n",
    "        \n",
    "\n",
    "import torch\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_fil,Y_fil,test_size = 0.2,random_state = 42)\n",
    "\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "x_train_tensor = normalize2(x_train_tensor)\n",
    "x_test_tensor = normalize2(x_test_tensor)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "\n",
    "# knn.fit(X_emb_train_priv, Y_train)\n",
    "\n",
    "# y_pred = knn.predict(X_emb_test)\n",
    "# print((y_pred == np.asarray(y_test_tensor)).sum()/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=68, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the model architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(68, 64),  # Input layer with 100 input features and 64 output features\n",
    "    nn.ReLU(),  # Activation function\n",
    "    nn.Linear(64, 128),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(128,32),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(),# Activation function\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()# Output layer with 32 input features and 10 output features\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "** Formed Tensors and starting model training** \n",
      " \n",
      " \n",
      "tensor(2.3109) tensor(1.6135)\n",
      "tensor(2.0265) tensor(1.3295)\n",
      "tensor(1.9309) tensor(1.2345)\n",
      "tensor(1.8273) tensor(1.1307)\n",
      "tensor(1.6944) tensor(0.9983)\n",
      "tensor(1.5369) tensor(0.8412)\n",
      "tensor(1.3928) tensor(0.6969)\n",
      "tensor(1.3214) tensor(0.6259)\n",
      "tensor(1.3350) tensor(0.6395)\n",
      "tensor(1.3565) tensor(0.6621)\n",
      "tensor(1.3182) tensor(0.6239)\n",
      "tensor(1.2238) tensor(0.5300)\n",
      "tensor(1.1049) tensor(0.4111)\n",
      "tensor(1.0552) tensor(0.3617)\n",
      "tensor(1.0965) tensor(0.4032)\n",
      "tensor(1.1235) tensor(0.4307)\n",
      "tensor(1.0918) tensor(0.3993)\n",
      "tensor(1.0324) tensor(0.3403)\n",
      "tensor(0.9994) tensor(0.3071)\n",
      "tensor(1.0240) tensor(0.3324)\n",
      "tensor(1.0429) tensor(0.3519)\n",
      "tensor(1.0179) tensor(0.3266)\n",
      "tensor(0.9659) tensor(0.2754)\n",
      "tensor(0.9409) tensor(0.2506)\n",
      "tensor(0.9683) tensor(0.2779)\n",
      "tensor(0.9572) tensor(0.2667)\n",
      "tensor(0.9122) tensor(0.2223)\n",
      "tensor(0.8891) tensor(0.1995)\n",
      "tensor(0.9121) tensor(0.2227)\n",
      "tensor(0.9046) tensor(0.2159)\n",
      "tensor(0.8760) tensor(0.1872)\n",
      "tensor(0.8781) tensor(0.1902)\n",
      "tensor(0.8963) tensor(0.2077)\n",
      "tensor(0.8596) tensor(0.1721)\n",
      "tensor(0.8477) tensor(0.1603)\n",
      "tensor(0.8552) tensor(0.1683)\n",
      "tensor(0.8434) tensor(0.1567)\n",
      "tensor(0.8307) tensor(0.1443)\n",
      "tensor(0.8377) tensor(0.1522)\n",
      "tensor(0.8309) tensor(0.1451)\n",
      "tensor(0.8184) tensor(0.1314)\n",
      "tensor(0.8297) tensor(0.1445)\n",
      "tensor(0.8133) tensor(0.1283)\n",
      "tensor(0.8144) tensor(0.1296)\n",
      "tensor(0.8119) tensor(0.1277)\n",
      "tensor(0.8045) tensor(0.1196)\n",
      "tensor(0.8058) tensor(0.1222)\n",
      "tensor(0.8030) tensor(0.1191)\n",
      "tensor(0.8026) tensor(0.1189)\n",
      "tensor(0.7970) tensor(0.1144)\n",
      "tensor(0.7987) tensor(0.1151)\n",
      "tensor(0.7946) tensor(0.1126)\n",
      "tensor(0.7876) tensor(0.1045)\n",
      "tensor(0.7878) tensor(0.1064)\n",
      "tensor(0.7865) tensor(0.1047)\n",
      "tensor(0.7868) tensor(0.1059)\n",
      "tensor(0.7766) tensor(0.0965)\n",
      "tensor(0.7842) tensor(0.1036)\n",
      "tensor(0.7809) tensor(0.1005)\n",
      "tensor(0.7849) tensor(0.1045)\n",
      "tensor(0.7749) tensor(0.0953)\n",
      "tensor(0.7781) tensor(0.0994)\n",
      "tensor(0.7746) tensor(0.0957)\n",
      "tensor(0.7843) tensor(0.1053)\n",
      "tensor(0.7708) tensor(0.0925)\n",
      "tensor(0.7817) tensor(0.1029)\n",
      "tensor(0.7679) tensor(0.0880)\n",
      "tensor(0.7667) tensor(0.0910)\n",
      "tensor(0.7754) tensor(0.0960)\n",
      "tensor(0.7740) tensor(0.0983)\n",
      "tensor(0.7657) tensor(0.0872)\n",
      "tensor(0.7630) tensor(0.0871)\n",
      "tensor(0.7702) tensor(0.0940)\n",
      "tensor(0.7670) tensor(0.0908)\n",
      "tensor(0.7703) tensor(0.0937)\n",
      "Test Accuracy:  tensor(0.7438)\n",
      "tensor(0.7438)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n** Formed Tensors and starting model training** \\n \\n \")\n",
    "net = Net_new(1,device = torch.device('cuda:3'))\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(x_train_tensor, y_train_tensor)), batch_size=512, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "net = net.to(device=torch.device('cuda:3'))\n",
    "\n",
    "train_model_priv(net,trainloader,x_test_tensor,y_test_tensor,optimizer,1,0.8,device= torch.device('cuda:3'),print_cond = True,only_reg_flag=0,lr_schedular =None,lambda_loss=1)\n",
    "outputs = net(x_test_tensor)\n",
    "print(((outputs>0.5).squeeze().cpu() == y_test_tensor.squeeze()).sum()/(len(y_test_tensor)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2394)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor.sum()/len(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ** Creating embeddings ** \n",
      " \n",
      "  38900\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n ** Creating embeddings ** \\n \\n \",len(y_train_tensor))\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(x_train_tensor, y_train_tensor)), batch_size=512, shuffle=False)\n",
    "X_emb_train, losses_train = create_model_embs2(net,trainloader,device= torch.device('cuda:3'),l=len(y_train_tensor),h=0.8)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "# x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "testloader = torch.utils.data.DataLoader(list(zip(x_test_tensor, y_test_tensor)), batch_size=512, shuffle=False)\n",
    "X_emb_test, losses_test = create_model_embs2(net,testloader,device= torch.device('cuda:3'),l=len(y_test_tensor),h=0.8)\n",
    "losses_train,indices = torch.sort(losses_train)\n",
    "\n",
    "# x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "# x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ** Starting final training ** \n",
      " \n",
      " \n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.8070)\n",
      "Test Accuracy:  tensor(0.8225)\n",
      "Test Accuracy:  tensor(0.8219)\n",
      "Test Accuracy:  tensor(0.8277)\n",
      "Test Accuracy:  tensor(0.8277)\n",
      "Test Accuracy:  tensor(0.8273)\n",
      "Test Accuracy:  tensor(0.8283)\n",
      "Test Accuracy:  tensor(0.8278)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_eps = 0.5\n",
    "ind = (losses_train < set_eps).sum()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "X_emb_train_priv = X_emb_train[indices][:ind]\n",
    "Y_train = y_train_tensor[indices][:ind]\n",
    "\n",
    "# input_size = 68\n",
    "# model = LogisticRegression(input_size)\n",
    "# Define the model architecture\n",
    "num_epochs = 10\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(68, 64),  # Input layer with 100 input features and 64 output features\n",
    "    nn.ReLU(),  # Activation function\n",
    "    nn.Linear(64, 128),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(128,32),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(),# Activation function\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()# Output layer with 32 input features and 10 output features\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainloader_priv = torch.utils.data.DataLoader(list(zip(X_emb_train_priv, Y_train)), batch_size=512, shuffle=True)\n",
    "print(\"\\n \\n ** Starting final training ** \\n \\n \")\n",
    "train_emb(model,trainloader_priv,X_emb_test,y_test_tensor,nn.BCELoss(),optimizer,num_epochs,device=torch.device('cuda:0'),test_total_loader = None,max_steps =10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n",
      "Test Accuracy:  tensor(0.7606)\n"
     ]
    }
   ],
   "source": [
    "input_size = 68\n",
    "num_epochs = 50\n",
    "# model = LogisticRegression(input_size)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(68, 64),  # Input layer with 100 input features and 64 output features\n",
    "    nn.ReLU(),  # Activation function\n",
    "    nn.Linear(64, 128),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(128,32),  # Hidden layer with 64 input features and 32 output features\n",
    "    nn.ReLU(),# Activation function\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()# Output layer with 32 input features and 10 output features\n",
    ")\n",
    "from opacus import PrivacyEngine\n",
    "privacy_engine = PrivacyEngine()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model2, optimizer2, data_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=trainloader,\n",
    "    target_epsilon=1,\n",
    "    target_delta =0.0001,\n",
    "    epochs = num_epochs,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "train_emb(model2,data_loader,x_test_tensor,y_test_tensor,nn.BCELoss(),optimizer2,num_epochs,device=torch.device('cuda:0'),max_steps =10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8252107752416205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_tensor)\n",
    "(predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240797861402427"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_emb_train_priv, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_emb_test)\n",
    "(predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8267530331071355\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "# data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# # Split the dataset into features and target variable\n",
    "# X = data.drop('income', axis=1)\n",
    "# y = data['income']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_emb_train_priv, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_emb_test)\n",
    "\n",
    "print(\"Accuracy:\", (predictions == np.array(y_test_tensor)).sum()/(len(y_test_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
